---
title: "Analyses"
format: html
editor: visual
editor_options: 
  chunk_output_type: console
---

```{r setup}
options(digits = 4)
options(scipen = 999)

filtered_baseline_data <- read_csv("Data/filtered_baseline_data.csv")
```


```{r acceptability}
#Acceptability total overall
filtered_baseline_data %>%
  summarize(
    mean_total = mean(pi_pfs_sum),
    sd_total = sd(pi_pfs_sum),
    mean_item = mean_total / 7,
    sd_item = sd_total / 7)

#Acceptability by item overall
filtered_baseline_data %>%
  select(pi_pfs_1:pi_pfs_7) %>%
  pivot_longer(everything()) %>%
  group_by(name) %>%
  summarize(mean = mean(value), 
            sd = sd(value))

#Acceptability total English
filtered_baseline_data %>%
  filter(language == "English") %>% 
  summarize(
    mean_total = mean(pi_pfs_sum),
    sd_total = sd(pi_pfs_sum),
    mean_item = mean_total / 7,
    sd_item = sd_total / 7)

#Acceptability by item English
filtered_baseline_data %>%
   filter(language == "English") %>% 
  select(pi_pfs_1:pi_pfs_7) %>%
  pivot_longer(everything()) %>%
  group_by(name) %>%
  summarize(mean = mean(value), 
            sd = sd(value))

#Acceptability total Spanish
filtered_baseline_data %>%
  filter(language == "Spanish") %>% 
  summarize(
    mean_total = mean(pi_pfs_sum),
    sd_total = sd(pi_pfs_sum),
    mean_item = mean_total / 7,
    sd_item = sd_total / 7)

#Acceptability by item Spanish
filtered_baseline_data %>%
   filter(language == "Spanish") %>% 
  select(pi_pfs_1:pi_pfs_7) %>%
  pivot_longer(everything()) %>%
  group_by(name) %>%
  summarize(mean = mean(value), 
            sd = sd(value))

#Acceptability total More Education
filtered_baseline_data %>%
  filter(dem_education_dichotomized == "More Education") %>% 
  summarize(
    mean_total = mean(pi_pfs_sum),
    sd_total = sd(pi_pfs_sum),
    mean_item = mean_total / 7,
    sd_item = sd_total / 7)

#Acceptability by item More Education
filtered_baseline_data %>%
   filter(dem_education_dichotomized == "More Education") %>% 
  select(pi_pfs_1:pi_pfs_7) %>%
  pivot_longer(everything()) %>%
  group_by(name) %>%
  summarize(mean = mean(value), 
            sd = sd(value))

#Acceptability total Less Education
filtered_baseline_data %>%
  filter(dem_education_dichotomized == "Less Education") %>% 
  summarize(
    mean_total = mean(pi_pfs_sum),
    sd_total = sd(pi_pfs_sum),
    mean_item = mean_total / 7,
    sd_item = sd_total / 7)

#Acceptability by item Less Education
filtered_baseline_data %>%
   filter(dem_education_dichotomized == "Less Education") %>% 
  select(pi_pfs_1:pi_pfs_7) %>%
  pivot_longer(everything()) %>%
  group_by(name) %>%
  summarize(mean = mean(value), 
            sd = sd(value))
```

```{r acceptability - individual level}
#Historgrams of acceptability ratings for each item
pfs_long <- filtered_baseline_data %>%
  filter(!is.na(pi_pfs_sum)) %>%
  select(Participant_ID, language, dem_education_dichotomized, pi_pfs_1:pi_pfs_7) %>%
  pivot_longer(
    cols = starts_with("pi_pfs_"),
    names_to = "item",
    values_to = "score"
  ) %>%
  mutate(
    item = str_remove(item, "^pi_pfs_"),
    item = paste0("Item ", item),
    item = factor(item, levels = paste0("Item ", 1:7)))

pfs_long_by_item_plot <- ggplot(pfs_long, aes(x = score, fill = language)) +
  geom_bar(position = "dodge") +
  facet_wrap(~ item, ncol = 3) +
  theme_minimal(base_size = 12) +
  labs(
    x = "Acceptability Score",
    y = "Participant Count",
    fill = "Language",
    title = "Distribution of Acceptability Scores by Item"
  ) +
  scale_fill_manual(values = c("English" = "steelblue", "Spanish" = "firebrick")) +
  scale_x_continuous(breaks = 1:5) + 
  scale_y_continuous(breaks = seq(0, 25, 2)) +
    theme(panel.spacing = unit(1, "lines"))
#ggsave("~/Desktop/pfs_long_by_item_plot.png", plot = pfs_long_by_item_plot, width = 8, height = 6, units = "in", dpi = 300)

pfs_long_by_item_plot2 <- ggplot(pfs_long, aes(x = score, fill = dem_education_dichotomized)) +
  geom_bar(position = "dodge") +
  facet_wrap(~ item, ncol = 3) +
  theme_minimal(base_size = 12) +
  labs(
    x = "Acceptability Score",
    y = "Participant Count",
    fill = "Education",
    title = "Distribution of Acceptability Scores by Item"
  ) +
  scale_fill_manual(values = c("More Education" = "darkgreen", "Less Education" = "darkgoldenrod1")) +
  scale_x_continuous(breaks = 1:5) + 
  scale_y_continuous(breaks = seq(0, 25, 2)) +
    theme(panel.spacing = unit(1, "lines"))

#Plot of each participant's overall acceptability rating
pfs_average_scores <- filtered_baseline_data %>%
  filter(!is.na(pi_pfs_sum)) %>%
  mutate(
    acceptability_mean = pi_pfs_sum / 7
  ) %>%
  select(Participant_ID, language, dem_education_dichotomized, acceptability_mean)

pfs_average_scores_plot <- ggplot(pfs_average_scores, aes(x = "", y = acceptability_mean, color = language)) +
  geom_jitter(width = 0.2, height = 0, size = 3) +
   geom_hline(
    yintercept = mean(pfs_average_scores$acceptability_mean, na.rm = TRUE),
    linetype = "dashed",
    color = "black",
    size = 1
  ) +
  theme_minimal(base_size = 12) +
  labs(
    x = NULL,
    y = "Mean Acceptability Score",
    title = "Overall Acceptability by Participant",
    color = "Language"
  ) +
  scale_y_continuous(limits = c(1, 5), breaks = seq(1, 5, 0.5)) +
  scale_color_manual(values = c("English" = "steelblue", "Spanish" = "firebrick")) +
  theme(
    axis.text.x = element_blank(),
    axis.ticks.x = element_blank()
  )
#ggsave("~/Desktop/pfs_average_scores_plot.png", plot = pfs_average_scores_plot, width = 8, height = 6, units = "in", dpi = 300)

pfs_average_scores_plot2 <- ggplot(pfs_average_scores, aes(x = "", y = acceptability_mean, color = dem_education_dichotomized)) +
  geom_jitter(width = 0.2, height = 0, size = 3) +
   geom_hline(
    yintercept = mean(pfs_average_scores$acceptability_mean, na.rm = TRUE),
    linetype = "dashed",
    color = "black",
    size = 1
  ) +
  theme_minimal(base_size = 12) +
  labs(
    x = NULL,
    y = "Mean Acceptability Score",
    title = "Overall Acceptability by Participant",
    color = "Education Level"
  ) +
  scale_y_continuous(limits = c(1, 5), breaks = seq(1, 5, 0.5)) +
  scale_color_manual(values = c("More Education" = "darkgreen", "Less Education" = "darkgoldenrod1")) +
  theme(
    axis.text.x = element_blank(),
    axis.ticks.x = element_blank()
  )
```

```{r patterns of use}
###Completion of study activities###

baseline_data %>% 
  select(Participant_ID) %>% 
  count()
filtered_baseline_data %>% 
  select(Participant_ID) %>% 
  count()
#28 participants were invited, 25 were compensated/included per completion.

baseline_data %>% 
  filter(is.na(`Baseline Measures Complete`)) %>% 
  count()
baseline_data %>% 
  filter(is.na(`Intervention Complete`)) %>% 
  count()
baseline_data %>% 
  filter(is.na(`Post-Intervention Measures Complete`)) %>% 
  count()
#The 3 participants who were not compensated/included consented but never completed the baseline measures, intervention, or post-intervention measures.

filtered_baseline_data %>% 
  filter(is.na(`Baseline Measures Complete`)) %>% 
  count()
filtered_baseline_data %>% 
  filter(is.na(`Intervention Complete`)) %>% 
  count()
filtered_baseline_data %>% 
  filter(is.na(`Post-Intervention Measures Complete`)) %>% 
  count()
#Verifying that the 25 compensated/included participants passed all checkpoints (they did)

###Duration of SSI###

##Without handling outliers
names_in_order <- filtered_baseline_data %>%
  select(ends_with("Page Submit")) %>%
  names()

#Put mean duration and sd for each page into a new data frame
page_durations <- filtered_baseline_data %>% 
  select(ends_with("Page Submit")) %>%
    mutate(across(everything(), ~ as.numeric(as.character(.)))) %>%
  pivot_longer(cols = everything(),
               names_to = "page",
               values_to = "duration") %>%
  group_by(page) %>%
  summarise(mean_duration = mean(duration, na.rm = T),
            sd_duration = sd(duration,  na.rm = T), .groups = "drop") 
page_durations #the Mean and SD of seconds spent on each page of the SSI

#Summarize duration
mean_sd_durations <- page_durations %>%
  summarize(mean_duration_seconds = sum(mean_duration, na.rm = TRUE), 
            sd_duration_seconds = sum(sd_duration, na.rm = TRUE), 
            .groups = "drop") %>%
  mutate(mean_duration_minutes = mean_duration_seconds / 60,
         sd_duration_minutes = sd_duration_seconds / 60)
mean_sd_durations #huge SD even larger than the mean

##With handling outliers

#Look for outliers 
page_durations_long <- filtered_baseline_data %>% 
  select(ends_with("Page Submit")) %>%
  mutate(across(everything(), ~ as.numeric(as.character(.)))) %>%
  pivot_longer(cols = everything(),
               names_to = "page",
               values_to = "duration")
ggplot(page_durations_long, aes(x = page, y = duration)) +
  geom_boxplot(outlier.color = "red", outlier.shape = 16, outlier.size = 2) +
  theme_minimal() +
  labs(title = "Page Durations with Outliers",
       x = "Page",
       y = "Duration (seconds)")
#The data is super skewed with people keeping a page open for 1000+ seconds, so we will log transform it for visual clarity
ggplot(page_durations_long, aes(x = page, y = log(duration))) +
  geom_boxplot(outlier.color = "red", outlier.shape = 16, outlier.size = 2) +
  theme_minimal() +
  labs(title = "Page Durations with Outliers",
       x = "Page",
       y = "Log of Duration (seconds)")

#IQR method on raw data (not log transformed data)
page_durations_no_outliers <- page_durations_long %>%
  group_by(page) %>%
  mutate(
    Q1 = quantile(duration, 0.25, na.rm = TRUE),
    Q3 = quantile(duration, 0.75, na.rm = TRUE),
    IQR = Q3 - Q1,
    lower = Q1 - 1.5 * IQR,
    upper = Q3 + 1.5 * IQR) %>%
  ungroup() %>%
  filter(duration >= lower & duration <= upper)

page_durations_no_outliers_summary <- page_durations_no_outliers %>%
  group_by(page) %>%
  summarize(
    mean_duration = mean(duration, na.rm = TRUE),
    sd_duration = sd(duration, na.rm = TRUE),
    .groups = "drop"
  )

mean_sd_durations_no_outliers <- page_durations_no_outliers_summary %>%
  summarize(
    mean_duration_seconds = sum(mean_duration, na.rm = TRUE), 
    sd_duration_seconds = sum(sd_duration, na.rm = TRUE)
  ) %>%
  mutate(
    mean_duration_minutes = mean_duration_seconds / 60,
    sd_duration_minutes = sd_duration_seconds / 60
  )
mean_sd_durations_no_outliers
```

```{r demographics}
filtered_baseline_data %>%
  count(dem_ethnicity) %>%
  mutate(percent = (n / sum(n))*100)

filtered_baseline_data %>%
  count(dem_relationship) %>%
  mutate(percent = (n / sum(n))*100)

filtered_baseline_data %>%
  count(dem_momdad) %>%
  mutate(percent = (n / sum(n))*100)

filtered_baseline_data %>%
  count(dem_marital) %>%
  mutate(percent = (n / sum(n))*100)

filtered_baseline_data %>%
  count(dem_education) %>%
  mutate(percent = (n / sum(n))*100)

filtered_baseline_data %>%
  count(dem_caretaking) %>%
  mutate(percent = (n / sum(n))*100)

#Only asked if dem_caretaking is Yes/1
filtered_baseline_data %>%
  count(dem_live) %>%
  mutate(percent = (n / sum(n))*100)

filtered_baseline_data %>%
  count(dem_income) %>%
  mutate(percent = (n / sum(n))*100)

filtered_baseline_data %>%
  count(dem_familyhx) %>%
  mutate(percent = (n / sum(n))*100)

#Age as categories
filtered_baseline_data %>%
  count(dem_childage) %>%
  mutate(percent = (n / sum(n))*100)

#Age as mean/SD
filtered_baseline_data %>% 
  summarise(mean = mean(dem_childage, na.rm = TRUE),
            sd = sd(dem_childage, na.rm = TRUE))

filtered_baseline_data %>%
  count(dem_childgrade) %>%
  mutate(percent = (n / sum(n))*100)

filtered_baseline_data %>%
  count(dem_childsex) %>%
  mutate(percent = (n / sum(n))*100)

childgender_tibble <- filtered_baseline_data %>%
  select(starts_with("dem_childgender")) %>% 
  summarize(across(everything(), 
                   list(n = ~ sum(. == 1),
                        percent = ~ mean(. == 1) * 100))) #child gender is select all that apply
View(childgender_tibble)

filtered_baseline_data %>%
  count(dem_childethnicity) %>%
  mutate(percent = (n / sum(n))*100)

##REDO - PULL FROM CHART##
filtered_baseline_data %>%
  count(dem_childinsurance) %>%
  mutate(percent = (n / sum(n))*100)

##REDO - PULL FROM CHART##
#Only asked if dem_childinsurance is Yes/1
filtered_baseline_data %>%
  count(dem_insurancetype) %>%
  mutate(percent = (n / sum(n))*100)

##REDO - PULL FROM CHART##
#Only asked if dem_childinsurance is Yes/1
filtered_baseline_data %>%
  count(dem_coverage) %>%
  mutate(percent = (n / sum(n))*100)

filtered_baseline_data %>%
  count(dem_outofpocket) %>%
  mutate(percent = (n / sum(n))*100)

filtered_baseline_data %>%
  count(dem_childEDtx) %>%
  mutate(percent = (n / sum(n))*100)

#Only asked if dem_childEDtx is Yes/1
filtered_baseline_data %>%
  select(starts_with("dem_txtype")) %>% 
  summarize(across(everything(), 
                   list(n = ~ sum(. == 1),
                        percent = ~ mean(. == 1) * 100))) #EDtx type is select all that apply

filtered_baseline_data %>%
  count(dem_medical) %>%
  mutate(percent = (n / sum(n))*100)

filtered_baseline_data %>% 
  summarise(mean = mean(dem_admitlength, na.rm = TRUE),
            sd = sd(dem_admitlength, na.rm = TRUE))

filtered_baseline_data %>% 
  summarise(mean = mean(dem_admitbmi, na.rm = TRUE),
            sd = sd(dem_admitbmi, na.rm = TRUE))

psych_tibble <- filtered_baseline_data %>%
  select(starts_with("dem_psych")) %>% 
  summarize(across(everything(), 
                   list(n = ~ sum(. == 1),
                        percent = ~ mean(. == 1) * 100))) #co-occuring psych is select all that apply
View(psych_tibble)
```
